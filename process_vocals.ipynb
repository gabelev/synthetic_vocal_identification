{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100",
      "authorship_tag": "ABX9TyNhIfhNHqXg/GklmbsNQ/3k",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gabelev/synthetic_vocal_identification/blob/main/process_vocals.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XucR6eMpcFXw"
      },
      "outputs": [],
      "source": [
        "# Authorize me\n",
        "from google.colab import auth\n",
        "auth.authenticate_user()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# %%capture\n",
        "# Install some dependencies if in colab\n",
        "!%apt install ffmpeg\n",
        "%pip install spleeter\n",
        "%pip install tdqm\n",
        "%pip install torchaudio\n",
        "%pip install librosa\n",
        "%pip install safetensors\n",
        "%pip install pyannote.audio\n",
        "%pip install pyannote.core[notebook]\n",
        "%pip install tensorflow==2.9.1\n",
        "%pip install pyannote.pipeline==1.5.2\n"
      ],
      "metadata": {
        "id": "MJry2WfKcLK6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!gsutil -m cp -r gs://singer-id/ai_vocal_id_files ."
      ],
      "metadata": {
        "id": "HD2eDFhncNiW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c0922c78-0458-4de0-aa8a-5e1a68a7c9ea"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Copying gs://singer-id/ai_vocal_id_files/-Vo2vDsFdfw.mp3...\n",
            "/ [0/21 files][    0.0 B/ 76.8 MiB]   0% Done                                   \rCopying gs://singer-id/ai_vocal_id_files/0xoPoN-Etgg.mp3...\n",
            "/ [0/21 files][    0.0 B/ 76.8 MiB]   0% Done                                   \rCopying gs://singer-id/ai_vocal_id_files/5BfB3YRzMwo.mp3...\n",
            "/ [0/21 files][    0.0 B/ 76.8 MiB]   0% Done                                   \rCopying gs://singer-id/ai_vocal_id_files/5IYpleg9hJk.mp3...\n",
            "/ [0/21 files][    0.0 B/ 76.8 MiB]   0% Done                                   \rCopying gs://singer-id/ai_vocal_id_files/7QdxDJxJuAc.mp3...\n",
            "/ [0/21 files][    0.0 B/ 76.8 MiB]   0% Done                                   \rCopying gs://singer-id/ai_vocal_id_files/C0Mja5SdZEk.mp3...\n",
            "/ [0/21 files][    0.0 B/ 76.8 MiB]   0% Done                                   \rCopying gs://singer-id/ai_vocal_id_files/GjsSzqAWFAU.mp3...\n",
            "/ [0/21 files][    0.0 B/ 76.8 MiB]   0% Done                                   \rCopying gs://singer-id/ai_vocal_id_files/HGV-H-mgK60.mp3...\n",
            "/ [0/21 files][    0.0 B/ 76.8 MiB]   0% Done                                   \rCopying gs://singer-id/ai_vocal_id_files/IQscAY8-9vg.mp3...\n",
            "/ [0/21 files][    0.0 B/ 76.8 MiB]   0% Done                                   \rCopying gs://singer-id/ai_vocal_id_files/Lr8HJ3oW9-8.mp3...\n",
            "/ [0/21 files][    0.0 B/ 76.8 MiB]   0% Done                                   \rCopying gs://singer-id/ai_vocal_id_files/PWQG3mwH8i8.mp3...\n",
            "/ [0/21 files][    0.0 B/ 76.8 MiB]   0% Done                                   \rCopying gs://singer-id/ai_vocal_id_files/SDR9GuT_86w.mp3...\n",
            "/ [0/21 files][    0.0 B/ 76.8 MiB]   0% Done                                   \rCopying gs://singer-id/ai_vocal_id_files/U-y6K8X3hYM.mp3...\n",
            "/ [0/21 files][    0.0 B/ 76.8 MiB]   0% Done                                   \rCopying gs://singer-id/ai_vocal_id_files/XENVZRVzQNQ.mp3...\n",
            "/ [0/21 files][    0.0 B/ 76.8 MiB]   0% Done                                   \rCopying gs://singer-id/ai_vocal_id_files/YNy8VqlPX6Q.mp3...\n",
            "/ [0/21 files][    0.0 B/ 76.8 MiB]   0% Done                                   \rCopying gs://singer-id/ai_vocal_id_files/ZSQBxafzkX0.mp3...\n",
            "/ [0/21 files][    0.0 B/ 76.8 MiB]   0% Done                                   \rCopying gs://singer-id/ai_vocal_id_files/acEXM41m9mM.mp3...\n",
            "/ [0/21 files][    0.0 B/ 76.8 MiB]   0% Done                                   \rCopying gs://singer-id/ai_vocal_id_files/cOBSJKRrMYw.mp3...\n",
            "/ [0/21 files][    0.0 B/ 76.8 MiB]   0% Done                                   \rCopying gs://singer-id/ai_vocal_id_files/dcGKHNDRHkw.mp3...\n",
            "/ [0/21 files][    0.0 B/ 76.8 MiB]   0% Done                                   \rCopying gs://singer-id/ai_vocal_id_files/mF1PkR8uZ2Y.mp3...\n",
            "Copying gs://singer-id/ai_vocal_id_files/uQnn0aRTnJc.mp3...\n",
            "| [21/21 files][ 76.8 MiB/ 76.8 MiB] 100% Done   6.9 MiB/s ETA 00:00:00         \n",
            "Operation completed over 21 objects/76.8 MiB.                                    \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# !mkdir music/"
      ],
      "metadata": {
        "id": "ZfnZ4daOvh4r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# !tar -xf /content/singer-id/artist20-mp3s-32k.tgz -C music/"
      ],
      "metadata": {
        "id": "SJOziv_avklM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir ai_vocal_id_tensors/"
      ],
      "metadata": {
        "id": "aerWLornvnP9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "HF_TOKEN = \"hf_???\""
      ],
      "metadata": {
        "id": "4v9VvKkEkaNs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import librosa\n",
        "import os\n",
        "import torch\n",
        "import torchaudio\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "from pyannote.audio import Inference\n",
        "from pyannote.audio import Model\n",
        "from spleeter.separator import Separator\n",
        "from tqdm import tqdm\n",
        "\n",
        "\n",
        "model = Model.from_pretrained(\n",
        "    \"pyannote/embedding\",\n",
        "    use_auth_token=HF_TOKEN,\n",
        ")\n",
        "embedding_model = Inference(model, window=\"whole\")\n",
        "separator = Separator('spleeter:2stems')\n",
        "sample_rate = 16_000\n",
        "\n",
        "\n",
        "def pre_process_new(\n",
        "            input_file,\n",
        "            separator,\n",
        "            embedding_model,\n",
        "            sample_rate=16_000,\n",
        "            remove_silences=True,  # used for training prep\n",
        "            normalize=False,  # Probably always good to do\n",
        "            mono=True,\n",
        "            embedding=True,\n",
        "            verbose=False,\n",
        "    ):\n",
        "        # Load audio\n",
        "        # raw_audio, sr = torchaudio.load(input_file, channels_first=False)\n",
        "        raw_audio, sr = librosa.load(input_file, sr=sample_rate, mono=mono)\n",
        "        if verbose:\n",
        "            print(f\"Loaded audio {input_file}, sample_rate: {sr}\")\n",
        "\n",
        "        # Tony's Bug -- let's handle mono files\n",
        "        if raw_audio.shape[0] != 2:\n",
        "            raw_audio = np.array([raw_audio,raw_audio])\n",
        "\n",
        "        raw_audio = np.swapaxes(raw_audio, 0, 1)\n",
        "\n",
        "        # removed vocals\n",
        "        prediction = separator.separate(raw_audio)\n",
        "        vox = prediction[\"vocals\"]\n",
        "        #audio = vox\n",
        "\n",
        "        audio = np.swapaxes(vox, 0, 1)\n",
        "        # remove silences\n",
        "        if remove_silences:\n",
        "            no_silences = librosa.effects.trim(\n",
        "                y=audio, frame_length=8000, top_db=40)\n",
        "            audio = no_silences[0]\n",
        "\n",
        "        if normalize:\n",
        "            # normailze the volume\n",
        "            audio = librosa.util.normalize(audio, axis=0)\n",
        "\n",
        "        # convert to torch tensor\n",
        "        audio = torch.from_numpy(audio)\n",
        "\n",
        "        #make mono again?\n",
        "        if mono:\n",
        "            audio = torch.mean(audio, dim=0, keepdim=True)\n",
        "\n",
        "        if embedding:\n",
        "            embedding = embedding_model({\"waveform\": audio, \"sample_rate\": sample_rate})\n",
        "            return embedding\n",
        "        return audio"
      ],
      "metadata": {
        "id": "_6jYyCWEfP__",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b80a15d3-3561-4530-bf14-4ff462d8c87e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:pytorch_lightning.utilities.migration.utils:Lightning automatically upgraded your loaded checkpoint from v1.2.7 to v2.2.4. To apply the upgrade to your files permanently, run `python -m pytorch_lightning.utilities.upgrade_checkpoint ../root/.cache/torch/pyannote/models--pyannote--embedding/snapshots/4db4899737a38b2d618bbd74350915aa10293cb2/pytorch_model.bin`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model was trained with pyannote.audio 0.0.1, yours is 3.2.0. Bad things might happen unless you revert pyannote.audio to 0.x.\n",
            "Model was trained with torch 1.8.1+cu102, yours is 2.2.1+cu121. Bad things might happen unless you revert torch to 1.x.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:pytorch_lightning.utilities.migration.utils:Lightning automatically upgraded your loaded checkpoint from v1.2.7 to v2.2.4. To apply the upgrade to your files permanently, run `python -m pytorch_lightning.utilities.upgrade_checkpoint ../root/.cache/torch/pyannote/models--pyannote--embedding/snapshots/4db4899737a38b2d618bbd74350915aa10293cb2/pytorch_model.bin`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model was trained with pyannote.audio 0.0.1, yours is 3.2.0. Bad things might happen unless you revert pyannote.audio to 0.x.\n",
            "Model was trained with torch 1.8.1+cu102, yours is 2.2.1+cu121. Bad things might happen unless you revert torch to 1.x.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from safetensors.torch import save_file\n",
        "\n",
        "\n",
        "# TODO cycle through files and create safe tensors of the embeddings and save them somewhere\n",
        "def run_pre_process(root_directory, output_path):\n",
        "    for subdir, dirs, files in tqdm(os.walk(rootdir)):\n",
        "        for f in files:\n",
        "            embedding = pre_process_new(os.path.join(subdir, f), separator, embedding_model)\n",
        "            torch_embedding = torch.from_numpy(embedding)\n",
        "            data = {\n",
        "                    \"tensor\": torch_embedding,\n",
        "                }\n",
        "            # sub = subdir.split(\"/\")[-2]\n",
        "            fname = f.split(\".\")[0]\n",
        "            output_file_name = f\"{fname}.safetensors\"\n",
        "            save_file(data, output_path + output_file_name)\n"
      ],
      "metadata": {
        "id": "KY0z9s4wqv32"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# MUST delete list file\n",
        "rootdir = \"/content/ai_vocal_id_files\"\n",
        "output_dir = \"ai_vocal_id_tensors/\"\n",
        "run_pre_process(rootdir, output_dir)"
      ],
      "metadata": {
        "id": "JgYMtruwvunN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "77a59e05-bc86-4de9-b045-b2eb37fbfd51"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r0it [00:00, ?it/s]WARNING:tensorflow:From /usr/local/lib/python3.10/dist-packages/spleeter/separator.py:146: calling DatasetV2.from_generator (from tensorflow.python.data.ops.dataset_ops) with output_types is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use output_signature instead\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.10/dist-packages/spleeter/separator.py:146: calling DatasetV2.from_generator (from tensorflow.python.data.ops.dataset_ops) with output_shapes is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use output_signature instead\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.10/dist-packages/keras/layers/normalization/batch_normalization.py:514: _colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n",
            "1it [04:46, 286.52s/it]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!gsutil -m cp -r ai_vocal_id_tensors/ gs://singer-id"
      ],
      "metadata": {
        "id": "X4B7Z109xLbv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "00975316-5e5a-4bff-e5ee-74630a5cac9f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Copying file://ai_vocal_id_tensors/YNy8VqlPX6Q.safetensors [Content-Type=application/octet-stream]...\n",
            "/ [0/21 files][    0.0 B/ 43.5 KiB]   0% Done                                   \rCopying file://ai_vocal_id_tensors/uQnn0aRTnJc.safetensors [Content-Type=application/octet-stream]...\n",
            "/ [0/21 files][    0.0 B/ 43.5 KiB]   0% Done                                   \rCopying file://ai_vocal_id_tensors/IQscAY8-9vg.safetensors [Content-Type=application/octet-stream]...\n",
            "/ [0/21 files][    0.0 B/ 43.5 KiB]   0% Done                                   \rCopying file://ai_vocal_id_tensors/acEXM41m9mM.safetensors [Content-Type=application/octet-stream]...\n",
            "Copying file://ai_vocal_id_tensors/mF1PkR8uZ2Y.safetensors [Content-Type=application/octet-stream]...\n",
            "Copying file://ai_vocal_id_tensors/C0Mja5SdZEk.safetensors [Content-Type=application/octet-stream]...\n",
            "Copying file://ai_vocal_id_tensors/PWQG3mwH8i8.safetensors [Content-Type=application/octet-stream]...\n",
            "Copying file://ai_vocal_id_tensors/Lr8HJ3oW9-8.safetensors [Content-Type=application/octet-stream]...\n",
            "Copying file://ai_vocal_id_tensors/dcGKHNDRHkw.safetensors [Content-Type=application/octet-stream]...\n",
            "Copying file://ai_vocal_id_tensors/5BfB3YRzMwo.safetensors [Content-Type=application/octet-stream]...\n",
            "Copying file://ai_vocal_id_tensors/5IYpleg9hJk.safetensors [Content-Type=application/octet-stream]...\n",
            "Copying file://ai_vocal_id_tensors/HGV-H-mgK60.safetensors [Content-Type=application/octet-stream]...\n",
            "Copying file://ai_vocal_id_tensors/ZSQBxafzkX0.safetensors [Content-Type=application/octet-stream]...\n",
            "Copying file://ai_vocal_id_tensors/cOBSJKRrMYw.safetensors [Content-Type=application/octet-stream]...\n",
            "Copying file://ai_vocal_id_tensors/-Vo2vDsFdfw.safetensors [Content-Type=application/octet-stream]...\n",
            "Copying file://ai_vocal_id_tensors/7QdxDJxJuAc.safetensors [Content-Type=application/octet-stream]...\n",
            "Copying file://ai_vocal_id_tensors/0xoPoN-Etgg.safetensors [Content-Type=application/octet-stream]...\n",
            "Copying file://ai_vocal_id_tensors/XENVZRVzQNQ.safetensors [Content-Type=application/octet-stream]...\n",
            "Copying file://ai_vocal_id_tensors/SDR9GuT_86w.safetensors [Content-Type=application/octet-stream]...\n",
            "Copying file://ai_vocal_id_tensors/U-y6K8X3hYM.safetensors [Content-Type=application/octet-stream]...\n",
            "Copying file://ai_vocal_id_tensors/GjsSzqAWFAU.safetensors [Content-Type=application/octet-stream]...\n",
            "| [21/21 files][ 43.5 KiB/ 43.5 KiB] 100% Done   3.7 KiB/s ETA 00:00:00         \n",
            "Operation completed over 21 objects/43.5 KiB.                                    \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "FBlc_mnGyZoo"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}